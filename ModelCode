# Import necessary libraries
import torch
import torch.optim as optim
import numpy as np
import pandas as pd
import os, random
from transformers import ViTForImageClassification
from torch.utils.data import DataLoader, Dataset
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image
from torchvision import transforms
from sklearn.model_selection import train_test_split

# 1. Data Loading (same as provided for HAM and ISIC datasets)
PROCESSED_IMAGES_DIR = '/kaggle/input/processed-imagesdataset/processed_images'
HAM_LABELS_CSV = '/kaggle/input/labeldataset/labelsDataSet/labels.csv'
ISIC_LABELS_CSV = '/kaggle/input/labeldataset/labelsDataSet/isic_labels.csv'

ham_l = pd.read_csv(HAM_LABELS_CSV)
ham_l['source'] = 'HAM'
isic_l = pd.read_csv(ISIC_LABELS_CSV)
isic_l['source'] = 'ISIC'
data_df = pd.concat([ham_l, isic_l], ignore_index=True)

# 2. Label Cleaning & Mapping to 8 classes (ensure only the necessary 8 classes)
label_mapping = {
    "melanocytic nevi": "Melanocytic Nevus",
    "nv": "Melanocytic Nevus",
    "melanoma": "Melanoma",
    "mel": "Melanoma",
    "benign keratosis": "Benign Keratosis",
    "bkl": "Benign Keratosis",
    "basal cell carcinoma": "Basal Cell Carcinoma",
    "bcc": "Basal Cell Carcinoma",
    "actinic keratosis": "Actinic Keratosis",
    "akiec": "Actinic Keratosis",
    "dermatofibroma": "Dermatofibroma",
    "df": "Dermatofibroma",
    "vascular lesions": "Vascular Lesion",
    "vasc": "Vascular Lesion",
    "warts/molluscum": "Warts/Molluscum"
}
data_df['dx'] = data_df['dx'].str.lower().map(label_mapping)
data_df = data_df.dropna(subset=['dx']).reset_index(drop=True)
data_df['label'] = data_df['dx']

# Verify unique classes
unique_classes = sorted(data_df['label'].unique())
num_classes = len(unique_classes)
print(f"Unique classes ({num_classes}): {unique_classes}")
assert num_classes == 8, "Error: The dataset does not have exactly 8 classes after label mapping!"

# 3. Image Path Resolution (same as provided)
all_files = set(os.listdir(PROCESSED_IMAGES_DIR))

def resolve_path(img_id):
    variants = [img_id, img_id.lower(), img_id.upper(), f"ISIC_{img_id}", f"HAM_{img_id}"]
    for var in variants:
        for ext in [".jpg", ".png", ""]:
            candidate = var + ext if not var.endswith(ext) else var
            if candidate in all_files:
                return os.path.join(PROCESSED_IMAGES_DIR, candidate)
    return None

data_df['filepath'] = data_df['image_id'].apply(resolve_path)
data_df = data_df.dropna(subset=['filepath']).reset_index(drop=True)

# 4. Add another dataset with only one folder (no CSV)
ACNE_IMAGES_DIR = '/kaggle/input/acne-dataset/Acne'  # Assuming a folder with only images
image_files = [f for f in os.listdir(ACNE_IMAGES_DIR) if f.endswith('.jpg') or f.endswith('.png')]

# Create a dataframe for this new dataset with the same label for all images
acne_data = pd.DataFrame({
    'filepath': [os.path.join(ACNE_IMAGES_DIR, f) for f in image_files],
    'label': ['Acne'] * len(image_files)
})

# Combine the original data with the new dataset
data_df = pd.concat([data_df, acne_data], ignore_index=True)

# 5. Add additional dataset with directory structure (6 classes)
train_dir_2 = '/kaggle/input/skin-diseases/kaggle/train'
val_dir_2 = '/kaggle/input/skin-diseases/kaggle/val'
test_dir_2 = '/kaggle/input/skin-diseases/kaggle/test'

# Check the directories for the second dataset
print(f"Train directory exists: {os.path.exists(train_dir_2)}")
print(f"Validation directory exists: {os.path.exists(val_dir_2)}")
print(f"Test directory exists: {os.path.exists(test_dir_2)}")

# 6. Data generators for the second dataset (Dataset 2)
IMG_SIZE = 224
BATCH_SIZE = 32

train_datagen_2 = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.2,
    brightness_range=(0.8, 1.2)
)

val_datagen_2 = ImageDataGenerator(rescale=1./255)

# Dataset 2 - Data Generators (train, val, test)
train_gen_2 = train_datagen_2.flow_from_directory(
    train_dir_2, 
    target_size=(IMG_SIZE, IMG_SIZE), 
    class_mode='categorical', 
    batch_size=BATCH_SIZE, 
    shuffle=True
)

val_gen_2 = val_datagen_2.flow_from_directory(
    val_dir_2, 
    target_size=(IMG_SIZE, IMG_SIZE), 
    class_mode='categorical', 
    batch_size=BATCH_SIZE, 
    shuffle=False
)

test_gen_2 = val_datagen_2.flow_from_directory(
    test_dir_2, 
    target_size=(IMG_SIZE, IMG_SIZE), 
    class_mode='categorical', 
    batch_size=BATCH_SIZE, 
    shuffle=False
)

# Combine the second dataset (Dataset 2) with the original dataframe
skin_data_2 = []
for class_name in os.listdir(train_dir_2):
    class_folder_path = os.path.join(train_dir_2, class_name)
    if os.path.isdir(class_folder_path):  # Check if it's a folder (class)
        # Get image paths for this class
        image_files = [os.path.join(class_folder_path, f) for f in os.listdir(class_folder_path) if f.endswith('.jpg') or f.endswith('.png')]
        for image_file in image_files:
            skin_data_2.append({
                'filepath': image_file,
                'label': class_name  # Use folder name as the label
            })

# Convert to DataFrame
skin_data_2_df = pd.DataFrame(skin_data_2)

# Combine with the original dataframe
data_df = pd.concat([data_df, skin_data_2_df], ignore_index=True)

# 7. Model Definition using ViT and PyTorch
def build_model():
    model = ViTForImageClassification.from_pretrained(
        "google/vit-base-patch16-224-in21k",  # Pre-trained ViT model from Hugging Face
        num_labels=15  # Total number of classes: 8 from HAM/ISIC, 1 from Acne, 6 from Dataset 2
    )
    return model

# 8. Load pre-trained model weights
vit_model = build_model()

# Load the model weights from the local path (model.bin)
model_path = '/kaggle/input/skin-disease-classification-model-vit/pytorch/default/1/pytorch_model.bin'
vit_model.load_state_dict(torch.load(model_path))

# Set the model to evaluation mode before making predictions
vit_model.eval()

# 9. Data Transformation and Loading (using PyTorch)
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Pre-trained ViT norms
])

# Custom dataset class
class CustomDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.dataframe = dataframe
        self.transform = transform
        self.label_encoder = LabelEncoder()
        self.dataframe['encoded_label'] = self.label_encoder.fit_transform(self.dataframe['label'])

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        img_path = self.dataframe.iloc[idx]['filepath']
        
        # Check if the path is a directory
        if os.path.isdir(img_path):
            print(f"Skipping directory: {img_path}")  # Skipping directories
            return None
        
        img = Image.open(img_path).convert("RGB")
        label = self.dataframe.iloc[idx]['encoded_label']
        
        if self.transform:
            img = self.transform(img)
        
        return img, torch.tensor(label)

train_dataset = CustomDataset(data_df, transform=transform)
val_dataset = CustomDataset(data_df, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# 10. Training Setup with Early Stopping
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
vit_model.to(device)

# Loss function and optimizer
optimizer = optim.Adam(vit_model.parameters(), lr=1e-4)
criterion = torch.nn.CrossEntropyLoss()

num_epochs = 9  # You can change this to the required number of epochs
early_stopping = EarlyStopping(patience=5, min_delta=0.001)  # Stop if no improvement for 5 epochs

for epoch in range(num_epochs):
    vit_model.train()  # Set the model to training mode
    running_loss = 0.0
    correct_train = 0
    total_train = 0
    
    # Training loop
    for images, labels in train_loader:
        if images is None:  # Skip invalid (None) images due to directories
            continue

        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        
        outputs = vit_model(images).logits
        loss = criterion(outputs, labels)
        
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        
        _, predicted = torch.max(outputs, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

    # Calculate training accuracy
    train_accuracy = 100 * correct_train / total_train
    
    # Validation loop with classification report
    vit_model.eval()
    correct_val = 0
    total_val = 0
    val_loss = 0.0
    y_true_val = []
    y_pred_val = []

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)

            outputs = vit_model(images).logits
            loss = criterion(outputs, labels)
            val_loss += loss.item()

            _, predicted = torch.max(outputs, 1)

            total_val += labels.size(0)
            correct_val += (predicted == labels).sum().item()

            y_true_val.extend(labels.cpu().numpy())
            y_pred_val.extend(predicted.cpu().numpy())

    val_accuracy = 100 * correct_val / total_val
    avg_val_loss = val_loss / len(val_loader)

    print(f"Epoch [{epoch+1}/{num_epochs}], "
          f"Train Loss: {running_loss/len(train_loader):.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Validation Loss: {avg_val_loss:.4f}, "
          f"Validation Accuracy: {val_accuracy:.2f}%")

    # Print classification report for validation set
    label_names = train_dataset.label_encoder.classes_
    print("\nClassification Report (Validation):")
    print(classification_report(y_true_val, y_pred_val, target_names=label_names))

    # Early stopping check
    if early_stopping(avg_val_loss):
        print(f"Early stopping at epoch {epoch+1}")
        break

# Evaluation on the Test Dataset
y_true = []
y_pred = []

vit_model.eval()
with torch.no_grad():
    for images, labels in test_gen_2:
        images = torch.tensor(images).to(device)
        labels = torch.tensor(labels).to(device)

        outputs = vit_model(images).logits
        _, predicted = torch.max(outputs, 1)

        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', xticklabels=test_gen_2.class_indices.keys(),
            yticklabels=test_gen_2.class_indices.keys())
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

report = classification_report(y_true, y_pred, target_names=test_gen_2.class_indices.keys())
print("Classification Report:\n", report)
